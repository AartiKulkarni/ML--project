import os
import imageio
import numpy as np
import tensorflow as tf
import tensorflow.keras as kr
from IPython import display
from PIL import Image
from glob import glob
import matplotlib.pyplot as plt
from google.colab import files

"""## Hyperparams"""

LatentDim = 100
BatchSize = 50
SampleInterval = 200
Epoch = 5000

"""## Loading Data"""

# Only loading the 60000 training samples as they should be enough for our application
(X, _), (_, _) = kr.datasets.mnist.load_data()

# Reshaping and Casting dtype
X = X.reshape(X.shape[0], 28, 28, 1).astype('float32')
X = (X - 127.5) / 127.5

"""## Generator Model"""

def createGenerator(output=(28,28,1)):
  """
  Each unit in the generator has a Dense Layer with LeakyRelu activation and BatchNormalization layer. 
  The sequential generator model has 3 such units and an output unit with dimernsions (784,1) [equal to the image dimension].
  """
  
  model = kr.Sequential(name='generator')
  
  model.add(kr.layers.Dense(256, input_shape=(LatentDim, )))
  model.add(kr.layers.LeakyReLU(alpha=0.2))
  model.add(kr.layers.BatchNormalization(momentum=0.8))

  model.add(kr.layers.Dense(512))
  model.add(kr.layers.LeakyReLU(alpha=0.2))
  model.add(kr.layers.BatchNormalization(momentum=0.8))

  model.add(kr.layers.Dense(1024))
  model.add(kr.layers.LeakyReLU(alpha=0.2))
  model.add(kr.layers.BatchNormalization(momentum=0.8))

  model.add(kr.layers.Dense(784, activation='tanh'))
  model.add(kr.layers.Reshape(output))

  return model

generator = createGenerator()
generator.summary()

"""## Discriminator Model"""

def createDiscriminator(input = (28,28,1)):
  """
  Each unit in the discriminator has a Dense Layer with LeakyRelu activation. 
  Prior to passing the input, the image is flattened and then connected to the Dense Layer of the first unit.
  The sequential generator model has 3 such units and an output unit uses Sigmoid.
  """

  model = kr.Sequential(name='discriminator')

  model.add(kr.layers.Flatten(input_shape=input))
  model.add(kr.layers.Dense(1024))
  model.add(kr.layers.LeakyReLU(alpha=0.2))
  
  model.add(kr.layers.Dense(512))
  model.add(kr.layers.LeakyReLU(alpha=0.2))
  

  model.add(kr.layers.Dense(256))
  model.add(kr.layers.LeakyReLU(alpha=0.2))

  model.add(kr.layers.Dense(1, activation='sigmoid'))

  return model


discriminator = createDiscriminator()
discriminator.summary()

# Using Adam optimizers with learning rate and beta value
optimizer = kr.optimizers.Adam(0.0002, 0.5)

discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,  metrics=['acc'])
discriminator.trainable = False    

z = kr.Input(shape=(LatentDim,)) 
valid = discriminator(generator(z))

model = kr.Model(z, valid)
model.compile(loss='binary_crossentropy', optimizer=optimizer)
model.summary()

"""### Function for plotting, displaying and saving the images generated by the generator"""

def plotUtil(images, epoch, save, name):
  fig, ax = plt.subplots(4, 4)
  x = 0
  for i in range(4):
    for j in range (4):
      ax[i, j].imshow(generatorImages[x, :,:,0], cmap = 'gray')
      ax[i, j].axis('off')
      x += 1

  if save : 
    file_name = f"{name}_{epoch}.png"
    fig.savefig(file_name)
    files.download(file_name)

  plt.show()


def renderImageFromGenerator(generator, epoch, save = True, name = 'mnist_gen'):
  """
  Generates an image using a generator object(Keras model)
  Option to save the image or just displaying it
  """
  # Creating generator images
  noise = np.random.normal(size = (4 * 4, LatentDim))
  generatorImages = generator.predict(noise)
  generatorImages = 0.5*generatorImages+0.5
  # Plotting the images in subplots
  plotUtil(generatorImages, epoch, save, name)

"""## Training and saving intermediate results"""

realLabel = np.ones((BatchSize, 1))
fakeLabel = np.zeros((BatchSize, 1))

genLossHistory, discLossHistory = [], []

for epoch in range(Epoch):
  noise = np.random.normal(size = (BatchSize, LatentDim))
  images = X[np. random.randint(0, X.shape[0], BatchSize)]
  
  realLoss = discriminator.train_on_batch(images, realLabel)
  fakeLoss = discriminator.train_on_batch(generator.predict(noise), fakeLabel)
  discriminator_loss, discriminator_accuracy = 0.5 * np.add(realLoss, fakeLoss)

  noise = np.random.normal(size = (BatchSize, LatentDim))
  generator_loss = model.train_on_batch(noise, realLabel)
  display.clear_output(wait = True)

  discLossHistory.append(discriminator_loss)
  genLossHistory.append(generator_loss)
  print ("Epoch number : %d [Discriminator loss: %f, accuracy.: %.2f%%] [Generator loss: %f]" % (epoch, discriminator_loss, 100*discriminator_accuracy, generator_loss))

  if epoch % SampleInterval == SampleInterval-1:
        createImages(generator, epoch, name=f'intermediate_{epoch}', save=True)

"""### Plotting generator loss and discriminator loss as a function of epochs"""

def plotLoss(genLossHistory, discLossHistory, epochs=Epoch):
  """
  Plots and saves the generator and discriminator loss plots for the 
  specified number of epochs
  """
  plot_name = f"loss_plot-{epochs}.png"

  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Generator Loss and Discriminator Loss varying with Epoch')
  plt.plot(genLossHistory, "-b", label="Generator Loss")
  plt.plot(discLossHistory, "-r", label="Discriminator Loss")
  plt.legend(loc="upper right")
  plt.savefig(plot_name, dpi=300, format="png")
  files.download(plot_name)

"""## Final sample image after the specified epochs"""

createImages(generator, None, save = False)

plotLoss(genLossHistory, discLossHistory)

